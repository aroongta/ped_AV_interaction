{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import ipdb\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('TkAgg')\n",
    "\n",
    "#TO-DO: Define LSTMNet\n",
    "\"\"\" Class for defining the LSTM Network \"\"\"\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\" Initialize the network here. You can use a combination of nn.LSTMCell and nn.Linear. \n",
    "        Number of layers and hidden size is upto you. Hint: A network with less than 3 layers and \n",
    "        64 dimensionality should suffice.\n",
    "        \"\"\"\n",
    "        s\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.hidden_dim=64 #taking hidden dimension=64\n",
    "        self.lstm1=nn.LSTMCell(1,self.hidden_dim) #defining the LSTM  unit1\n",
    "        self.lstm2=nn.LSTMCell(self.hidden_dim,self.hidden_dim) #defining the second layer LSTM unit2\n",
    "        self.linear=nn.Linear(self.hidden_dim,1) #fully connected layer\n",
    "        pass\n",
    " \n",
    "    def forward(self, obs_seq, pred_len = 0):\n",
    "        \"\"\" This function takes the input sequence and predicts the output sequence. \n",
    "            Arguments:\n",
    "                input_seq (torch.Tensor) : Input sequence with shape <batch size x sequence length x number of dimensions>\n",
    "                pred_len (int) : Length of the sequence to be predicted.\n",
    "\n",
    "        Hint: There should be 2 for loops. First one iterates over the observed sequence. Second one predicts the output sequence\n",
    "        one step at a time.\n",
    "\n",
    "        \"\"\"\n",
    "        output=[]\n",
    "        h_t=torch.zeros(obs_seq.size(0),self.hidden_dim,dtype=torch.double,requires_grad=False) #deifing the LSTM cell output variable\n",
    "        c_t=torch.zeros(obs_seq.size(0),self.hidden_dim,dtype=torch.double,requires_grad=False) #defining initial cell state variable\n",
    "        h_t2=torch.zeros(obs_seq.size(0),self.hidden_dim,dtype=torch.double,requires_grad=False) #defining the LSTM cell 2 output variable\n",
    "        c_t2=torch.zeros(obs_seq.size(0),self.hidden_dim,dtype=torch.double,requires_grad=False) #definnig final cell state variable for LST cell \n",
    "        for i,input_seq in enumerate(obs_seq.chunk(obs_seq.size(1),dim=1)): #iterating over the columns\n",
    "            h_t,c_t=self.lstm1(input_seq,(h_t,c_t)) #going through the first lstm layer\n",
    "            h_t2,c_t2=self.lstm2(h_t,(h_t2,c_t2)) #going through the second lstm layer\n",
    "            otpt=self.linear(h_t2) #fully connected layer\n",
    "            output+=[otpt]\n",
    "            \n",
    "        for i in range(pred_len): #beginning wiht test input and predicting future sequences\n",
    "            h_t,c_t=self.lstm1(otpt,(h_t,c_t)) #predicting the hidden state through first layer\n",
    "            h_t2,c_t2=self.lstm2(h_t,(h_t2,c_t2)) #predicting the output prediction\n",
    "            otpt=self.linear(h_t2) #fully connected layer\n",
    "            output+=[otpt]\n",
    "        \n",
    "        output=torch.stack(output,1).squeeze(2)\n",
    "        return output\n",
    "\n",
    "def getData():\n",
    "    \"\"\" Function to load the train and test data\n",
    "        Returns:\n",
    "            train_input (torch.Tensor): 95 x 99\n",
    "            train_target (torch.Tensor): 95 x 99\n",
    "            test_input (torch.Tensor): 5 x 99\n",
    "            test_target (torch.Tensor): 5 x 99\n",
    "    \"\"\"\n",
    "    data = torch.load('q4data.pt')\n",
    "    train_input = torch.from_numpy(data[5:, :-1])\n",
    "    train_target = torch.from_numpy(data[5:, 1:])\n",
    "    test_input = torch.from_numpy(data[:5, :-1])\n",
    "    test_target = torch.from_numpy(data[:5, 1:])\n",
    "    return train_input, train_target, test_input, test_target\n",
    "\n",
    "def plotTestResults(pred, epoch, obs_len=999, pred_len=999):\n",
    "    \"\"\" Function to plot the observed and predicted sequence\n",
    "        Arguments:\n",
    "            pred (torch.Tensor): 5 x 198\n",
    "            epoch (int): Epoch number\n",
    "            obs_len (int): Length of the observed sequence\n",
    "            pred_len (int): Length of the predicted sequence\n",
    "\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(32,20))\n",
    "    colors=['r','b','g','y','cyan','majenta','black','purple','grey','orange'] #list for storing different plot colors\n",
    "    plt.title(\"Observed and predicted values for time sequences || epoch: %d\"%epoch)\n",
    "    prediction=pred.data.numpy() #converting tensor to numpy array\n",
    "    for i in range(pred.size(0)):\n",
    "        plt.plot(np.arange(obs_len),prediction[i][range(obs_len)],color=colors[i])\n",
    "        plt.plot(np.arange(obs_len,obs_len+pred_len),prediction[i,range(obs_len,pred_len+obs_len)],color=colors[i],linestyle='--')\n",
    "    plt.show()\n",
    "    pass\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    num_epoch = 10\n",
    "    pred_freq = 1\n",
    "    pred_len = 999\n",
    "    \n",
    "    # Get data\n",
    "    train_input, train_target, test_input, test_target = getData()\n",
    "\n",
    "    # Define the network and criterion\n",
    "    net = LSTMNet()\n",
    "    net.double()\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer = optim.LBFGS(net.parameters(), lr=0.8)\n",
    "\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "\n",
    "    # Train for 'num_epoch' epochs and test every 'pred_freq' epochs. \n",
    "    # When predicting, use pred_len=999\n",
    "    # Plot test results everytime. At the end, you should have 'num_epoch' number of plots\n",
    "    \n",
    "    for i in range(num_epoch):\n",
    "        print('Epoch:{}'.format(i))\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            out = net(train_input)\n",
    "            loss = criterion(out, train_target)\n",
    "            print('loss:{}'.format(loss.item()))\n",
    "            train_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        optimizer.step(closure)\n",
    "    \n",
    "        if i%pred_freq == (pred_freq-1) :\n",
    "            pred = net(test_input, pred_len=pred_len)\n",
    "            loss = criterion(pred[:, :-pred_len], test_target)\n",
    "            test_loss.append(loss.item())\n",
    "            print('Test loss:', loss.item())\n",
    "            plotTestResults(pred, i)\n",
    "            \n",
    "\n",
    "    # TO-DO: Plot training loss v/s epoch\n",
    "    train_lossavg=[] #list to store mean training loss of each epoch\n",
    "    train_loss=np.asarray(train_loss)\n",
    "    for g in range(int(len(train_loss)/20)): #computing mean training loss of each epoch\n",
    "        train_lossavg.append(np.mean(train_loss[range(g*20,g*20+20)]))\n",
    "       \n",
    "    plt.figure()\n",
    "    print(\"Training loss v/s epoch\")\n",
    "    plt.plot(np.arange(len(train_lossavg)),train_lossavg)\n",
    "    plt.title(\"Traning loss v/s epoch\")\n",
    "    plt.ylabel(\"Training loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.show()\n",
    "    \n",
    "    # TO-DO: Plot test loss v/s epoch\n",
    "    plt.figure()\n",
    "    print(\"Test loss v/s epoch\")\n",
    "    plt.plot(np.arange(num_epoch),test_loss)\n",
    "    plt.title(\"Test loss v/s epoch\")\n",
    "    plt.ylabel(\"Test loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
