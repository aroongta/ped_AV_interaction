{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Class for defining the Vanilla LSTM Network \"\"\"\n",
    "class VanillaLSTMNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\" Initialize the network here. You can use a combination of nn.LSTMCell and nn.Linear. \n",
    "        Number of layers and hidden size is up to you. Hint: A network with less than 3 layers and \n",
    "        64 dimensionality should suffice.\n",
    "        \"\"\"\n",
    "        super(LSTMNet, self).__init__()\n",
    "        \n",
    "        # Inputs to the LSTMCell's are (input, (h_0, c_0)):\n",
    "        # 1. input of shape (batch, input_size): tensor containing input \n",
    "        # features\n",
    "        # 2a. h_0 of shape (batch, hidden_size): tensor containing the \n",
    "        # initial hidden state for each element in the batch.\n",
    "        # 2b. c_0 of shape (batch, hidden_size): tensor containing the \n",
    "        # initial cell state for each element in the batch.\n",
    "        \n",
    "        # Outputs: h_1, c_1\n",
    "        # 1. h_1 of shape (batch, hidden_size): tensor containing the next \n",
    "        # hidden state for each element in the batch\n",
    "        # 2. c_1 of shape (batch, hidden_size): tensor containing the next \n",
    "        # cell state for each element in the batch\n",
    "        \n",
    "        # set parameters for network architecture\n",
    "        embedding_size = 64\n",
    "        rnn_size = 128\n",
    "        input_size = 2\n",
    "        output_size = 2\n",
    "        dropout_prob = 0.5 \n",
    "        \n",
    "        # linear layer to embed the input position\n",
    "        self.input_embedding_layer = nn.Linear(input_size, embedding_size)\n",
    "        \n",
    "        # define lstm cell\n",
    "        # self.lstm_cell = nn.LSTMCell(embedding_size, rnn_size) # uncomment later for embedding\n",
    "        self.lstm_cell = nn.LSTMCell(embedding_size, embedding_size)\n",
    "\n",
    "        # linear layer to map the hidden state of LSTM to output\n",
    "        # self.output_layer = nn.Linear(rnn_size, output_size) # uncomment later for embedding\n",
    "        self.output_layer = nn.Linear(embedding_size, output_size)\n",
    "        \n",
    "        # ReLU and dropout unit\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        pass\n",
    " \n",
    "    def forward(self, observed_seq, pred_len = 0):\n",
    "        \"\"\" This function takes the input sequence and predicts the output sequence. \n",
    "        \n",
    "            args:\n",
    "                observed_seq (torch.Tensor) : Input sequence with shape <batch size x sequence length x number of dimensions>\n",
    "                pred_len (int) : Length of the sequence to be predicted.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        '''\n",
    "        Forward pass for the model\n",
    "        params:\n",
    "        input_data: Input positions\n",
    "        grids: Grid masks\n",
    "        hidden_states: Hidden states of the peds\n",
    "        cell_states: Cell states of the peds\n",
    "        PedsList: id of peds in each frame for this sequence\n",
    "        returns:\n",
    "        outputs_return: Outputs corresponding to bivariate Gaussian distributions\n",
    "        hidden_states\n",
    "        cell_states\n",
    "        '''\n",
    "        \n",
    "        output_seq = []\n",
    "        \n",
    "        # initialize cell states & hidden states\n",
    "        ht = torch.zeros(observed_seq.size(0), self.embedding_size, dtype=torch.double)\n",
    "        ct = torch.zeros(observed_seq.size(0), self.embedding_size, dtype=torch.double)\n",
    "        \n",
    "        # Iterate over the observed sequence, and predict output sequence one step at a time.\n",
    "        for i, input_seq in enumerate(observed_seq.chunk(observed_seq.size(1), dim=1)):\n",
    "            ht, ct = self.lstm_cell(input_seq, (ht, ct))\n",
    "            out = self.output_layer(ht)\n",
    "            output_seq += [out]\n",
    "            \n",
    "        for i in range(pred_len):\n",
    "            ht, ct = self.lstm_cell(out, (ht, ct))\n",
    "            out = self.output_layer(ht)\n",
    "            output_seq += [out]\n",
    "            \n",
    "        output_seq = torch.stack(output_seq, 1).squeeze(2) # convert list to tensor\n",
    "            \n",
    "        return output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # define parameters for training and testing loops\n",
    "    num_epoch = 100\n",
    "    pred_freq = 1\n",
    "    pred_len = 6\n",
    "    learning_rate = 0.003\n",
    "    \n",
    "    # get data\n",
    "    train_input, train_target, test_input, test_target = getData()\n",
    "\n",
    "    # define the network and criterion\n",
    "    vanilla_lstm_net = VanillaLSTMNet()\n",
    "    vanilla_lstm_net.double() # casts tensor to double\n",
    "    criterion = nn.MSELoss() # MSE works best for difference between predicted and actual coordinate paths\n",
    "\n",
    "    # define the optimizer\n",
    "    optimizer = optim.Adam(vanilla_lstm_net.parameters(), lr=learning_rate)\n",
    "\n",
    "    # initialize lists for capturing losses\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "\n",
    "    '''train for 'num_epoch' epochs and test every 'pred_freq' epochs & when predicting use pred_len=6'''\n",
    "    \n",
    "    for i in range(num_epoch):\n",
    "        print('========== Epoch: {cur_epoch} / {total_epochs} =========='.format(cur_epoch=i, total_epochs=num_epoch))\n",
    "        def closure():\n",
    "            optimizer.zero_grad() # zero out gradients\n",
    "            out = vanilla_lstm_net(train_input) # forward pass of lstm network for training\n",
    "            cur_train_loss = criterion(out, train_target) # calculate MSE loss\n",
    "            print('Current training loss: {}'.format(cur_train_loss.item())) # print current training loss\n",
    "            train_loss.append(loss.item())\n",
    "            loss.backward() # backward prop\n",
    "            return loss\n",
    "        optimizer.step(closure) # update weights\n",
    "    \n",
    "        # test the loop every pred_freq times\n",
    "        if i%pred_freq == (pred_freq-1) : \n",
    "            pred = vanilla_lstm_net(test_input, pred_len=pred_len) # forward pass of lstm network for testing\n",
    "            cur_test_loss = criterion(pred[:, :-pred_len], test_target)\n",
    "            test_loss.append(cur_test_loss.item())\n",
    "            print('Current test loss: {}'.format(cur_test_loss.item()))\n",
    "            # plotTestResults(pred, i)\n",
    "\n",
    "    ''' visualize losses vs. epoch'''\n",
    "                  \n",
    "    train_loss_avg = [] # only train loss, since test loss is already formatted\n",
    "\n",
    "    # plot training loss v/s epoch\n",
    "    plt.figure()\n",
    "    plt.title(\"Training loss (log scale) vs. epoch\")\n",
    "    \n",
    "    # loss is log-scaled for better visualization, since hits plateau quickly\n",
    "    for i in range(0,10):\n",
    "        train_loss_avg.append(sum(train_loss[i*20:(i+20)*20])/20)\n",
    "    plt.plot(list(range(1, num_epoch+1)), np.log(np.asarray(train_loss_avg)))\n",
    "    \n",
    "    # plot test loss v/s epoch\n",
    "    plt.figure()\n",
    "    plt.title(\"Test loss (log scale) vs. epoch\")\n",
    "    plt.plot(list(range(1, num_epoch+1)), np.log(np.asarray(test_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c7bc734e5e35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'main' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trajectories\n",
    "path1='/home/roongtaaahsih/ped_traj/self/datasets/eth/test/biwi_eth.txt'\n",
    "trajectories.read_file(pa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
